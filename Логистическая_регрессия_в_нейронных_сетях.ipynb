{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrew-veriga/Art048_NN_DAE/blob/main/%D0%9B%D0%BE%D0%B3%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F_%D0%B2_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D1%85_%D1%81%D0%B5%D1%82%D1%8F%D1%85.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrANl_yfif_R"
      },
      "source": [
        "Вы создадите классификатор логистической регрессии для распознавания кошек. Это задание расскажет, как это сделать с помощью нейронной сети, а также отточит вашу интуицию в отношении глубокого обучения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxeFhf0JiS_b"
      },
      "source": [
        "**Инструкции:**\n",
        "- Не используйте циклы (for / while) в своем коде, если только инструкции явно не требуют этого.\n",
        "\n",
        "**Вы научитесь:**\n",
        "- Создавать общую архитектуру алгоритма обучения, в том числе:\n",
        "  - Инициализация параметров\n",
        "  - Вычисление функции затрат и ее градиента\n",
        "  - Использование алгоритма оптимизации (градиентный спуск)\n",
        "- Собирать все эти три процедуры в основную функцию модели в правильном порядке.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMRyRa4_umRW"
      },
      "source": [
        "## 1 - Пакеты ##\n",
        "\n",
        "Во-первых, давайте запустим ячейку ниже, чтобы импортировать все пакеты, которые вам понадобятся во время этого назначения. \n",
        "- [numpy](https://numpy.org/) Это основной пакет для научных вычислений с Python.\n",
        "- [h5py](http://www.h5py.org) пакет для взаимодействия с набором данных, который хранится в файле H5.\n",
        "- [matplotlib](http://matplotlib.org)  знаменитая библиотека для построения графиков на Python.\n",
        "- [PIL](http://www.pythonware.com/products/pil/) and [scipy](https://www.scipy.org/) Используются здесь для проверки вашей модели с вашим собственным изображением в конце."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27R4u0vojBf9"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "import os     \n",
        "import urllib.request as url \n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "def load_dataset():\n",
        "    url.urlretrieve('https://github.com/andrew-veriga/Neural-Networks-and-Deep-Learning/raw/master/datasets/train_catvnoncat.h5', 'train_catvnoncat.h5')\n",
        "    train_dataset = h5py.File('train_catvnoncat.h5', \"r\")\n",
        "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
        "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
        "\n",
        "    url.urlretrieve('https://github.com/andrew-veriga/Neural-Networks-and-Deep-Learning/raw/master/datasets/test_catvnoncat.h5', 'test_catvnoncat.h5')\n",
        "    test_dataset = h5py.File('test_catvnoncat.h5', \"r\")\n",
        "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
        "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
        "\n",
        "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
        "    \n",
        "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "    \n",
        "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjT7KombjGJb"
      },
      "source": [
        "## 2 - Описание набора задач ##\n",
        "**Постановка задачи**: Вам предоставляется набор данных ('data.h5'), содержащий:\n",
        "- учебный набор из m_train с метками \"кошка\" (y=1) или \"не-кошка\" (y=0)\n",
        "- тестовый набор изображений m_test с метками  \"кошка\" или \"не кошка\"\n",
        "- каждое изображение имеет размерность (num_px, num_px, 3), где последнее число - это  3 канала (RGB). Таким образом, каждое изображение квадратное: высота = num_px и ширина = num_px.\n",
        "\n",
        "Вы построите простой алгоритм, который сможет правильно распознать изображение как кошку или не-кошку.\n",
        "\n",
        "Давайте поближе познакомимся с набором данных. Загрузите данные, запустив следующий код."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWj1FUIZjLhL"
      },
      "source": [
        "# Загрузка данных (cat/non-cat)\n",
        "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNA-fl7EjOfi"
      },
      "source": [
        "\n",
        "Мы добавили \"_orig\" в конце названий наборов данных изображений (тренировочного и тестового). После предварительной обработки, мы получим train_set_x и test_set_x (train_set_y и test_set_y не нуждаются в предварительной обработке).\n",
        "\n",
        "Каждая строка вашего train_set_x_orig test_set_x_orig - это массив, представляющий изображение. Вы можете визуализировать пример, запустив следующий код. Попробуйте также запускать с другими значениями `index`, чтобы увидеть другие изображения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbrMfzB-jTni"
      },
      "source": [
        "# Пример изоражения\n",
        "index = 19\n",
        "plt.imshow(train_set_x_orig[index])\n",
        "print (\"y = \" + str(train_set_y[:, index]) + \", it's a '\" + classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") +  \"' picture.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPr3vQOSjXBa"
      },
      "source": [
        "Многие программные ошибки в глубоком обучении связаны с несоответствием размерностей матриц и векторов. Если вы сможете разобраться с размерами матриц/векторов, вы сократите долгий путь по устранению многих ошибок. \n",
        "\n",
        "**Задание:** Найдите значения\n",
        "    - m_train (количестов обучающих примеров)\n",
        "    - m_test (количестов тестовых примеров)\n",
        "    - num_px (= высота = ширина обучающего изображения)\n",
        "Помните, что `train_set_x_orig` - это numpy-массив с размерностями (m_train, num_px, num_px, 3). Например, вы можете получить `m_train` вызвав `train_set_x_orig.shape[0]`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYUmrW_jjc6J"
      },
      "source": [
        "### НАЧАЛО ВАШЕГО КОДА ### (≈ 3 строки кода)\n",
        "m_train = \n",
        "m_test = \n",
        "num_px = \n",
        "### КОНЕЦ ВАШЕГО КОДА ###\n",
        "\n",
        "print (\"Number of training examples: m_train = \" + str(m_train))\n",
        "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
        "print (\"Height/Width of each image: num_px = \" + str(num_px))\n",
        "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
        "print (\"train_set_x shape: \" + str(train_set_x_orig.shape))\n",
        "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
        "print (\"test_set_x shape: \" + str(test_set_x_orig.shape))\n",
        "print (\"test_set_y shape: \" + str(test_set_y.shape))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaBTxxzcjmEy"
      },
      "source": [
        "**Ожидаемые значения для m_train, m_test and num_px**: \\\n",
        "```Python\n",
        "m_train 209\n",
        "m_test 50\n",
        "num_px 64\n",
        "```\n",
        "\n",
        "Для удобства теперь следует заменить изображения с форматом `(num_px, num_px, 3)` на массивы numpy с размерностями (num_px * num_px * 3, 1). После этого наш обучающий (и тестовый) набор данных станет массивом numpy, в котором каждый столбец представляет собой вектор. Должно получиться m_train (соответственно m_test) столбцов.\n",
        "\n",
        "**Упражнение:** Измените форму обучающих и тестовых наборов данных так, чтобы изображения размера (num_px, num_px, 3) вытянулись в отдельные векторы размерности (num _px\\*num _px\\*3, 1). \\\n",
        "\\\n",
        "Если вы хотите сгладить матрицу X формы (a,b,c,d) в матрицу X_flatten формы (b * c * d, a) используйте такой трюк:\n",
        "```python\n",
        "X_flatten = X.reshape(X.shape[0], -1).T      # X.T is the transpose of X\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TFeod81j7wo"
      },
      "source": [
        "# Изменение формы тренировочных и тестовых примеров\n",
        "\n",
        "### НАЧАЛО ВАШЕГО КОДА ### (≈ 2 строки кода)\n",
        "train_set_x_flatten =\n",
        "test_set_x_flatten =\n",
        "### ОКОНЧАНИЕ ВАШЕГО КОДА ###\n",
        "\n",
        "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
        "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
        "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
        "print (\"test_set_y shape: \" + str(test_set_y.shape))\n",
        "print (\"sanity check after reshaping: \" + str(train_set_x_flatten[0:5,0]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvoIgZD-j_-X"
      },
      "source": [
        "**Ожидаемый вывод**: \n",
        "```Python\n",
        "train_set_x_flatten shape (12288, 209)\n",
        "train_set_y shape (1, 209)\n",
        "test_set_x_flatten shape (12288, 50)\n",
        "test_set_y shape (1, 50)\n",
        "sanity check after reshaping  [17 31 56 22 33]\n",
        "```\n",
        "Чтобы представлять цветные изображения, красный, зеленый и синий каналы (RGB) должны быть указаны для каждого пикселя, и поэтому значение пикселя на самом деле вектор из трех чисел, начиная от 0 до 255.\n",
        "\n",
        "Во время обучения вашей модели модифицируете веса и добавите смещения к некоторым исходным входным данным, чтобы наблюдать активации нейронов. Затем вы используете градиенты для обучения модели. Чрезвычайно важно, чтобы все признаки находились в одинаковых диапазонах, чтобы наши градиенты не \"взрывались\". \n",
        "\n",
        "*О взрывающихся и исчезающих градиентах мы поговорим в последующих лекциях.*\n",
        "\n",
        "Давайте стандартизируем наш набор данных.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFxlKwUKkFE_"
      },
      "source": [
        "train_set_x = train_set_x_flatten/255.\n",
        "test_set_x = test_set_x_flatten/255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xxCCcvJkLc_"
      },
      "source": [
        "### **Что надо запомнить:**\n",
        "\n",
        "Общие шаги подготовки нового набора данных:\n",
        "- Выяснить размерности задачи (m_train, m_test, num_px, ...)\n",
        "- Изменить наборы данных таким образом, чтобы каждый пример теперь был вектором размергости (num_px * num_px * 3, 1)\n",
        "- «Стандартизировать» данные\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_teAgJvuy_f"
      },
      "source": [
        "\n",
        "##3 - Общая архитектура алгоритма обучения##\n",
        "\n",
        "Пришло время разработать простой алгоритм, различающий  изображения кошек и  не-кошек.\n",
        "\n",
        "Вы построите логистическую регрессию, используя логику нейронной сети. Следующая картинка объясняет, почему **Логистическая регрессия на самом деле очень простая нейронная сеть!**\n",
        "\n",
        "<img src=\"https://upscfever.com/upsc-fever/en/data/deeplearning/images/LogReg_kiank.png\" width=800>\n",
        "\n",
        "**Математическое представление алгоритма**:\n",
        "\n",
        "Для одного примера: $x^{(i)}$:\n",
        "$$\\begin{align}&z^{(i)} = w^T x^{(i)} + b \\tag{1} \\\\\n",
        "&\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\\tag{2} \\\\\n",
        "& \\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})\\tag{3}\\end{align}$$\n",
        "\n",
        "Затем потери вычисляются путем суммирования по всем примерам обучения:\n",
        "$$ J = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})\\tag{4}$$\n",
        "\n",
        "**Ключевые шаги**:\n",
        "\n",
        "В этом упражнении вы выполните следующие шаги:\n",
        "- Инициализировать параметры модели\n",
        "- Обучить параметры модели, минимизируя затраты\n",
        "- Использовать обученные параметры для прогнозирования (на тестовом наборе)\n",
        "- Проанализировать результаты и сделать вывод"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgBatQsEu8Bb"
      },
      "source": [
        "\n",
        "## 4 - Создание частей нашего алгоритма\n",
        "\n",
        "Основные шаги построения нейронной сети:\n",
        "1. Определить структуру модели (например, количество входных признаков)\n",
        "2. Инициализировать параметры модели\n",
        "3. Цикл:\n",
        "  - Рассчитать текущие потери (проход вперёд)\n",
        "  - Рассчитать текущий градиент (обратное распространение)\n",
        "  - Обновить параметры (градиентный спуск)\n",
        "\n",
        "Часто шаги 1-3 выполняются в одной функции, которую мы называем `model()`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSFAFUm5u-mM"
      },
      "source": [
        "\n",
        "### 4.1 - Вспомогательные функции\n",
        "\n",
        "**Упражнение:** реализуйте функцию `sigmoid()`. Как вы видели на рисунке выше, вам нужно вычислить $\\sigma( w^T x + b) = \\frac{1}{1 + e^{-(w^T x + b)}}$, чтобы делать прогнозы. Используйте np.exp().\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKpGwnk6lPX0"
      },
      "source": [
        "\n",
        "\n",
        "def sigmoid(z):\n",
        "    \"\"\"\n",
        "    Вычислить сигмоиду для z\n",
        "\n",
        "    Arguments:\n",
        "    z -- скаляр, или массив numpy\n",
        "\n",
        "    Return:\n",
        "    s -- sigmoid(z)\n",
        "    \"\"\"\n",
        "\n",
        "    ### НАЧАЛО ВАШЕГО КОДА ### (≈ 1 строка кода)\n",
        "    s = \n",
        "    ### ОКОНЧАНИЕ ВАШЕГО КОДА ###\n",
        "\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me53Nc4elS-k"
      },
      "source": [
        "print (\"sigmoid([0, 2]) = \" + str(sigmoid(np.array([0,2]))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE43DtyJlVd9"
      },
      "source": [
        "**Ожидаемый вывод**: \n",
        "```\n",
        "sigmoid([0, 2]) = [0.5        0.88079708]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7oe-7f0Aaq0"
      },
      "source": [
        "###4.2 - Инициализация параметров\n",
        "\n",
        "**Упражнение:** Вы должны инициализировать $w$ как вектор из нулей. Если вы не знаете, какую функцию использовать, посмотрите `np.zeros()` в документации библиотеки Numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaO99yqmlZyz"
      },
      "source": [
        "\n",
        "def initialize_with_zeros(dim):\n",
        "    \"\"\"\n",
        "    Эта функция создает вектор нулей формы (dim, 1) для w и инициализирует b равным 0.\n",
        "\n",
        "    Аргумент:\n",
        "    dim - размер вектора w, который нам нужен (или количество параметров в данном случае)\n",
        "\n",
        "    Возврат:\n",
        "    w - инициализированный вектор формы (dim, 1)\n",
        "    b - инициализированный скаляр (смещение)\n",
        "    \"\"\"\n",
        "    \n",
        "    ### НАЧАЛО ВАШЕГО КОДА ### (≈ 1 строка кода)\n",
        "    w =\n",
        "    b =\n",
        "    ### ОКОНЧАНИЕ ВАШЕГО КОДА ###\n",
        "\n",
        "    assert(w.shape == (dim, 1))\n",
        "    assert(isinstance(b, float) or isinstance(b, int))\n",
        "    \n",
        "    return w, b\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAnLmm0Jla27"
      },
      "source": [
        "dim = 2\n",
        "w, b = initialize_with_zeros(dim)\n",
        "print (\"w = \" + str(w))\n",
        "print (\"b = \" + str(b))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taYXiBfemYSK"
      },
      "source": [
        "**Ожидаемый вывод**: \n",
        "```\n",
        "w = [[0.]\n",
        " [0.]]\n",
        "b = 0\n",
        "```\n",
        "\n",
        "Для входных изображений `w` будет иметь форму (num_px $\\times$ num_px $\\times$ 3, 1).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZfjMrZCZuAw"
      },
      "source": [
        "\n",
        "### 4.3 - Распространение вперед и назад\n",
        "\n",
        "Теперь, когда ваши параметры инициализированы, вы можете сделать шаги распространения \"вперед\" и \"назад\"  для обучения параметров.\n",
        "\n",
        "**Упражнение:** Напишите функцию `propagate()`, которая вычисляет функцию затрат и ее градиент.\n",
        "\n",
        "(Подсказки):\n",
        "\n",
        "продвижение вперед:\n",
        "- получаете $X$\n",
        "- вычисляете $A = \\sigma(w^T X + b) = (a^{(0)}, a^{(1)}, ..., a^{(m-1)}, a^{(m)})$\n",
        "- вычисляете функцию затрат $J = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})$\n",
        "\n",
        " \n",
        "Вот две формулы, которые вы будете использовать:\n",
        "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T\\tag{7}$$\n",
        "$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{8}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfK6MZBHmeEC"
      },
      "source": [
        "def propagate(w, b, X, Y):\n",
        "    \"\"\"\n",
        "    Реализуйте функцию стоимости и ее градиент для распространения, описанного выше.\n",
        "\n",
        "    Arguments:\n",
        "    w - веса, массив размерностью (num_px * num_px * 3, 1)\n",
        "    b - смещение, скаляр\n",
        "    X - данные размера (num_px * num_px * 3, количество примеров)\n",
        "    Y - истинный вектор 'label' (содержащий 0, если не кошка, 1, если кошка) размера (1, количество примеров)\n",
        "\n",
        "    Return:\n",
        "    cost - стоимость отрицательного логарифма правдоподобия для логистической регрессии\n",
        "    dw - градиент функции затрат по w, такой же размерности, как и w\n",
        "    db - градиент потерь по b, такой же размерности, что и b\n",
        "\n",
        "    Подсказки:\n",
        "    - напишите свой код  для распространения шаг за шагом c с использованием np.log(), np.dot()\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[1]\n",
        "    \n",
        "    # FORWARD PROPAGATION (От X до получения затрат)\n",
        "    ### НАЧАЛО ВАШЕГО КОДА ### (≈ 2 строки кода)\n",
        "    A =                               # вычисляет активацию\n",
        "    cost =    # вычисляет затраты\n",
        "    ### ОКОНЧАНИЕ ВАШЕГО КОДА ###\n",
        "    \n",
        "    # BACKWARD PROPAGATION (поиск градиента)\n",
        "    ### НАЧАЛО ВАШЕГО КОДА ### (≈ 2 строк кода)\n",
        "    dw = \n",
        "    ### ОКОНЧАНИЕ ВАШЕГО КОДА ###\n",
        "\n",
        "    assert(dw.shape == w.shape)\n",
        "    assert(db.dtype == float)\n",
        "    cost = np.squeeze(cost)\n",
        "    assert(cost.shape == ())\n",
        "    \n",
        "    grads = {\"dw\": dw,\n",
        "             \"db\": db}\n",
        "    \n",
        "    return grads, cost\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy2dcxQqmh7a"
      },
      "source": [
        "w, b, X, Y = np.array([[1.],[2.]]), 2., np.array([[1.,2.,-1.],[3.,4.,-3.2]]), np.array([[1,0,1]])\n",
        "grads, cost = propagate(w, b, X, Y)\n",
        "print (\"dw = \" + str(grads[\"dw\"]))\n",
        "print (\"db = \" + str(grads[\"db\"]))\n",
        "print (\"cost = \" + str(cost))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnez8LVmmjE4"
      },
      "source": [
        "\n",
        "**Ожидаемый вывод**:\n",
        "```Python\n",
        "dw = [[0.99845601]\n",
        " [2.39507239]]\n",
        "db = 0.001455578136784208\n",
        "cost = 5.801545319394553\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-KQYUxlv-HP"
      },
      "source": [
        "### 4.4 - Оптимизация\n",
        "- Вы инициализировали свои параметры.\n",
        "- Вы можете вычислить функцию затрат и ее градиент.\n",
        "- Теперь вам надо обновить параметры, используя градиентный спуск.\n",
        "\n",
        "**Упражнение:** Напишите функцию оптимизации. Цель состоит в том, чтобы обучить $w$ и $b$, минимизируя функцию стоимости $J$. Для параметра $\\theta$ правило обновления: $ \\theta = \\theta - \\alpha \\ d\\theta$, где $\\alpha$ - скорость обучения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE9TgnCUmt-w"
      },
      "source": [
        "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
        "    \"\"\"\n",
        "    Эта функция оптимизирует w и b, запуская алгоритм градиентного спуска\n",
        "    Arguments:\n",
        "    w -- веса, numpy-массив размера (num_px * num_px * 3, 1)\n",
        "    b -- смещение, скаляр\n",
        "    X -- данные формы (num_px * num_px * 3, количество примеров)\n",
        "    Y -- вектор 'меток' (содержащий 0, если не кошка и 1, если кошка), формы (1, количество примеров)\n",
        "    Num_iterations - количество итераций цикла оптимизации\n",
        "    Learning_rate - скорость обучения правила обновления градиентного спуска\n",
        "    Print_cost - True, чтобы печатать потери каждые 100 шагов\n",
        "\n",
        "    Returns:\n",
        "    Params - словарь, содержащий веса w и смещение b\n",
        "    grads - словарь, содержащий градиенты весов и смещения относительно функции стоимости\n",
        "    costs - список всех затрат, рассчитанных во время оптимизации, будет использоваться для построения кривой обучения.\n",
        "        \n",
        "    Советы:\n",
        "    Вы должны записать два шага и итерировать их:\n",
        "    1) Рассчитать затраты и градиент для текущих параметров. Используйте propagate().\n",
        "    2) Обновить параметры с использованием правила градиентного спуска для w и b.\n",
        "    \"\"\"\n",
        "    \n",
        "    costs = []\n",
        "    \n",
        "    for i in range(num_iterations):\n",
        "        \n",
        "        \n",
        "        # Вычисление затрат и градиента (? 1-4 строк кода)\n",
        "        ### НАЧАЛО ВАШЕГО КОДА ### \n",
        "        grads, cost = \n",
        "        ### ОКОНЧАНИЕ ВАШЕГО КОДА ###\n",
        "        \n",
        "        # Получение производных из grads\n",
        "        dw = grads[\"dw\"]\n",
        "        db = grads[\"db\"]\n",
        "        \n",
        "        # обновить веса и смещение (? 2 строки кода)\n",
        "        ### НАЧАЛО ВАШЕГО КОДА ###\n",
        "        w -=\n",
        "        b -=\n",
        "        ### ОКОНЧАНИЕ ВАШЕГО КОДА ###\n",
        "        \n",
        "        # Записать затраты\n",
        "        if i % 100 == 0:\n",
        "            costs.append(cost)\n",
        "        \n",
        "        # Вывести затраты через каждых 100 обучающих примеров\n",
        "        if print_cost and i % 100 == 0:\n",
        "            print (\"Затраты после итерации %i: %f\" %(i, cost))\n",
        "    \n",
        "    params = {\"w\": w,\n",
        "              \"b\": b}\n",
        "    \n",
        "    grads = {\"dw\": dw,\n",
        "             \"db\": db}\n",
        "    \n",
        "    return params, grads, costs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpexZVgDmyN_"
      },
      "source": [
        "params_, grads_, costs_ = optimize(w, b, X, Y, num_iterations= 100, learning_rate = 0.009, print_cost = False)\n",
        "\n",
        "print (\"w = \" + str(params_[\"w\"]))\n",
        "print (\"b = \" + str(params_[\"b\"]))\n",
        "print (\"dw = \" + str(grads_[\"dw\"]))\n",
        "print (\"db = \" + str(grads_[\"db\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoIkT4rlnfE_"
      },
      "source": [
        "**Ожидаемый вывод**: \n",
        "\n",
        "``` Python\n",
        "w = [[0.19033591] \n",
        " [0.12259159]]\n",
        "b = 1.9253598300845747\n",
        "dw = [[0.67752042]\n",
        " [1.41625495]]\n",
        "db = 0.21919450454067652\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdVv708cA976"
      },
      "source": [
        "**Упражнение:** Предыдущая функция выведет обученные w и b. Мы можем использовать w и b для прогнозирования меток набора данных X. Реализуйте функцию `predict()`. Расчет прогнозов состоит из двух этапов:\n",
        "**Exercise:** The previous function will output the learned w and b. We are able to use w and b to predict the labels for a dataset X. Implement the `predict()` function. There is two steps to computing predictions:\n",
        "\n",
        "1. Вычисление $A = \\sigma(w^T X + b)$\n",
        "\n",
        "2. Конвертирование $A$ в 0 (если активация <= 0,5) или 1 (если активация > 0,5), \n",
        "3. сохранение прогнозы в векторе `Y_prediction`. При желании вы можете использовать оператор if / else в цикле for (хотя есть также способ векторизовать это)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4mjKaZboY-A"
      },
      "source": [
        "\n",
        "def predict(w, b, X):\n",
        "    '''\n",
        "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
        "    \n",
        "    Arguments:\n",
        "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
        "    b -- bias, a scalar\n",
        "    X -- data of size (num_px * num_px * 3, number of examples)\n",
        "    \n",
        "    Returns:\n",
        "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
        "    '''\n",
        "    \n",
        "    m = X.shape[1]\n",
        "    Y_prediction = np.zeros((1,m))\n",
        "    w = w.reshape(X.shape[0], 1)\n",
        "    \n",
        "    # Вычислить вектор A, предсказывающий вероятность присутствия кошки на картинке.\n",
        "    ### НАЧАЛО ВАШЕГО КОДА ### (? 1 строка кода)\n",
        "    A = \n",
        "    ### ОКОНЧАНИЕ ВАШЕГО КОДА ###\n",
        "    \n",
        "    for i in range(A.shape[1]):\n",
        "        \n",
        "        # Конвертировать вероятности A[0,i] в актуальные прогнозы Y[0,i]\n",
        "        ### НАЧАЛО ВАШЕГО КОДА ### (? 4 строк кода)\n",
        "\n",
        "           \n",
        "        ### ОКОНЧАНИЕ ВАШЕГО КОДА ###\n",
        "    \n",
        "    assert(Y_prediction.shape == (1, m))\n",
        "    \n",
        "    return Y_prediction\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or8yq7VQodMg"
      },
      "source": [
        "w_ = np.array([[0.1124579],[0.23106775]])\n",
        "b_ = -0.3\n",
        "X_ = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\n",
        "print (\"прогнозы = \" + str(predict(w_, b_, X_)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDawl4BnogsH"
      },
      "source": [
        "**Ожидаемый вывод**: \n",
        "\n",
        "`прогнозы:            [[ 1.  1.  0.]]`\n",
        "\n",
        "**Что надо запомнить:**\n",
        "\n",
        "Вы реализовали несколько функций, которые:\n",
        "- Инициализировали (w, b)\n",
        "- Итеративно оптимизировали затраты, обучив параметры (w, b):\n",
        "  - рассчитали функцию затрат и ее градиент\n",
        "  - произвели обновление параметров с помощью градиентного спуска\n",
        "- Использовали изученные (w, b), чтобы предсказать метки для данного набора примеров\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEgVDFpFovLA"
      },
      "source": [
        "## 5 - Объединим все функции в модель ##\n",
        "\n",
        "Теперь, собрав вместе все блоки (функции, реализованные в предыдущих частях), вы увидите всю структурированную модель.\n",
        "\n",
        "**Exercise:** Implement the model function. Use the following notation:\n",
        "**Упражнение.** Реализация модели. Используйте следующие обозначения:\n",
        "- Y_prediction для ваших прогнозов на тестовом наборе;\n",
        "- Y_prediction_train для ваших обучающего набора прогнозов;\n",
        "- w, costs, grads для выводов функции optimize()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv6_POYqo10Z"
      },
      "source": [
        "\n",
        "\n",
        "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
        "    \"\"\"\n",
        "    Builds the logistic regression model by calling the function you've implemented previously\n",
        "    \n",
        "    Arguments:\n",
        "    X_train -- тренировочный набор, представленный массивом numpy формы (num_px * num_px * 3, m_train)\n",
        "    Y_train -- обучающие метки, представленные массивом (вектором) numpy формы (1, m_train)\n",
        "    X_test --  тестовый набор, представленный массивом numpy формы (num_px * num_px * 3, m_test)\n",
        "    Y_test -- тестовые метки, представленные массивом (вектором) numpy формы (1, m_test)\n",
        "    num_iterations -- гиперпараметр, представляющий количество итераций для оптимизации параметров\n",
        "    learning_rate -- гиперпараметр \"скорость обучения\", используемый в функции оптимизации optimize()\n",
        "    print_cost -- Установите в true, чтобы выводить cost каждые 100 итераций.\n",
        "    \n",
        "    Returns:\n",
        "    d -- словарь, содержащий информацию о модели\n",
        "    \"\"\"\n",
        "    \n",
        "    ### НАЧАЛО ВАШЕГО КОДА ###\n",
        "    \n",
        "    # initialize parameters with zeros (~ 1 строка кода)\n",
        "        w, b = \n",
        "\n",
        "    # Gradient descent (~ 1 строка кода)\n",
        "    parameters, grads, costs = \n",
        "    \n",
        "    # получить параметры w and b из словаря \"parameters\"\n",
        "    w = \n",
        "    b = \n",
        "    \n",
        "    # тестовые/обучающие наборы примеров (~ 2 строки кода)\n",
        "    Y_prediction_test = \n",
        "    Y_prediction_train = \n",
        "\n",
        "    ### ОКОНЧАНИЕ ВАШЕГО КОДА ###\n",
        "\n",
        "    # Вывести точность данных на обучающем и тестовом наборах\n",
        "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
        "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
        "\n",
        "    \n",
        "    d = {\"costs\": costs,\n",
        "         \"Y_prediction_test\": Y_prediction_test, \n",
        "         \"Y_prediction_train\" : Y_prediction_train, \n",
        "         \"w\" : w, \n",
        "         \"b\" : b,\n",
        "         \"learning_rate\" : learning_rate,\n",
        "         \"num_iterations\": num_iterations}\n",
        "    \n",
        "    return d\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGWfQAplo68R"
      },
      "source": [
        "Запустите следующую ячейку для тренировки вашей модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RfzdrhYo-3A"
      },
      "source": [
        "d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5_SjqAypC7K"
      },
      "source": [
        "**Ожидаемый вывод**: \n",
        "```\n",
        "Потери после итерации 0: 0.693147\n",
        "...\n",
        "...\n",
        "...\n",
        "train accuracy: 99.04306220095694 %\n",
        "test accuracy: 70.0 %\n",
        "```\n",
        "\n",
        "**Комментарий**: точность обучения близка к 100%. Это хорошая проверка работоспособности: ваша модель работает и имеет достаточно высокую способность к совпадению с обучающими данными. Ошибка теста 68%. На самом деле это неплохо для такой простой модели, учитывая небольшой набор данных, который мы использовали, и то, что логистическая регрессия тут - простой линейный классификатор.\n",
        "\n",
        "\n",
        "Используя приведенный ниже код (и изменив переменную index), вы можете просматривать прогнозы на изображениях тестового набора.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2V3NTmjBqJG"
      },
      "source": [
        "classes[int(d[\"Y_prediction_test\"][0,index])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GbuCXTMs1uY"
      },
      "source": [
        "# Пример изображения которая ошибочно классифицируется.\n",
        "index = 1\n",
        "plt.imshow(test_set_x[:,index].reshape((num_px, num_px, 3)))\n",
        "print (\"y = \" + str(test_set_y[0,index]) + \", you predicted that it is a \\\"\" + classes[int(test_set_y[0,index])].decode(\"utf-8\") +  \"\\\" picture.\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZWQh260s4M4"
      },
      "source": [
        "Давайте нарисуем функцию затрат и градиент"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgQTSDYrs_cg"
      },
      "source": [
        "# Кривая процесса обучения (изменение затрат по мере итерации)\n",
        "costs = np.squeeze(d['costs'])\n",
        "plt.plot(costs)\n",
        "plt.ylabel('cost')\n",
        "plt.xlabel('iterations (per hundreds)')\n",
        "plt.title(\"Learning rate =\" + str(d[\"learning_rate\"]))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTL9qOdutX8n"
      },
      "source": [
        "**Интерпертация**:\n",
        "Вы можете видеть снижение потерь. Это показывает, что параметры обучаются. Однако тут видно, что вы можете лучше обучить модель на обучающей выборке. Попробуйте увеличить количество итераций в ячейке выше и перезапустите ячейки. Вы можете увидеть, что точность обучающего набора повышается, но точность набора тестов снижается. Это называется **overfitting**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo-jN-LStg-H"
      },
      "source": [
        "##6 - Дальнейший анализ (необязательное / упражнение)##\n",
        "\n",
        "Поздравляем с созданием вашей первой модели классификации изображений. Давайте проанализируем его дальше и рассмотрим возможные варианты изменения скорости обучения $\\alpha$.\n",
        "\n",
        "#### Выбор скорости обучения ####\n",
        "\n",
        "**Напоминание**:\n",
        "Чтобы градиентный спуск работал, вы должны осмысленно выбирать скорость обучения. Скорость обучения $\\alpha$ определяет, насколько быстро мы обновляем параметры. Если скорость обучения слишком велика, мы можем \"перескочить\" оптимальное значение. Точно так же, если она слишком мала, нам понадобится слишком много итераций, чтобы достичь хороших значений. Вот почему так важно использовать хорошо настроенную скорость обучения.\n",
        "\n",
        "Давайте сравним кривую обучения нашей модели с несколькими вариантами скорости обучения. Запустите ячейку ниже. Это займет около 1 минуты. Попробуйте также  значения, отличные от тех трех чисел, которыми мы инициализировали переменную `learning_rates`, и посмотреть, что произойдет."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itubPd8RtqER"
      },
      "source": [
        "learning_rates = [0.01, 0.001, 0.0001]\n",
        "models = {}\n",
        "for i in learning_rates:\n",
        "    print (\"learning rate is: \" + str(i))\n",
        "    models[str(i)] = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 1500, learning_rate = i, print_cost = False)\n",
        "    print ('\\n' + \"-------------------------------------------------------\" + '\\n')\n",
        "\n",
        "for i in learning_rates:\n",
        "    plt.plot(np.squeeze(models[str(i)][\"costs\"]), label= str(models[str(i)][\"learning_rate\"]))\n",
        "\n",
        "plt.ylabel('cost')\n",
        "plt.xlabel('iterations')\n",
        "\n",
        "legend = plt.legend(loc='upper center', shadow=True)\n",
        "frame = legend.get_frame()\n",
        "frame.set_facecolor('0.90')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w143Lgmptuxx"
      },
      "source": [
        "**Интерпретация**: \n",
        "- Разные скорости обучения приводят к разным затратам и, следовательно, к разным результатам прогнозов.\n",
        "- Если скорость обучения слишком велика (0,01), стоимость может колебаться вверх и вниз. Он может даже расходиться (хотя в этом примере использование 0,01 все равно в конечном итоге дает хорошее соотношение цены и качества).\n",
        "- Более низкие затраты не означает лучшую модель. Вы должны проверить, нет ли оверфиттинга. Это случается, когда точность на этапе обучения намного выше, чем точность на этапе тестирования.\n",
        "- При глубоком обучении мы обычно рекомендуем:\n",
        "     - Выберите скорость обучения, которая лучше минимизирует функцию затрат.\n",
        "     - При оверфиттинге используйте другие методы, чтобы уменьшить переобучение.\n",
        "\n",
        "## 7 - Проверка с вашим собственным изображением (дополнительное упражнение) ##\n",
        "\n",
        "\n",
        "Поздравляю с завершением этого задания. Вы можете использовать собственное изображение и увидеть результат своей модели. Для этого:\\\n",
        "     1. Нажмите «Файлы» на боковой панели этого ноутбука, затем нажмите \"загрузить в хранилище\".\\\n",
        "     2. Добавьте свое изображение в текущий каталог Jupyter Notebook.\\\n",
        "     3. Измените название изображения в следующем коде.\\\n",
        "     4. Запустите код и проверьте правильность алгоритма (1 = кошка, 0 = не кошка)!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6N7GS7bt0A3"
      },
      "source": [
        "import imageio\n",
        "from skimage.transform import resize\n",
        "## НАЧАЛО ВАШЕГО КОДА ## \n",
        "my_image = \"7_9c58af28.jpg\"   # измените на имя ВАШЕГО файла изображения с кошкой, или без кошки\n",
        "## ОКОНЧАНИЕ ВАШЕГО КОДА ##\n",
        "\n",
        "# Мы предварительно обработаем изображение, чтобы соответствовать вашему алгоритму.\n",
        "fname = \"images/\" + my_image\n",
        "image = np.array(plt.imread(fname))\n",
        "resized_image = resize(image, (num_px,num_px)).reshape((1, num_pxnum_px3)).T\n",
        "my_predicted_image = predict(d[\"w\"], d[\"b\"], resized_image)\n",
        "\n",
        "plt.imshow(image)\n",
        "print(\"y = \" + str(np.squeeze(my_predicted_image)) + \", your algorithm predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\\" picture.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of5LyQLvt8zH"
      },
      "source": [
        "**Что нужно помнить из этого задания:**\n",
        "1. Предварительная обработка набора данных важна.\n",
        "2. Вы реализовали каждую функцию отдельно: initialize(), propagate(), optimize(). Затем вы построили model().\n",
        "3. Настройка скорости обучения (которая является одним из т.н «гиперпараметров») может иметь большое значение для алгоритма. \n",
        "\n",
        "Наконец, если хотите, можете попробовать разные вещи в этом блокноте. - Играйте со скоростью обучения и количеством итераций\n",
        "- Попробуйте разные методы инициализации и сравните результаты\n",
        "- Протестируйте другие предварительные обработки (центрируйте данные или разделите каждую строку на ее стандартное отклонение)\n",
        "\n",
        "Справочная литература:\n",
        "- http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/\n",
        "- https://stats.stackexchange.com/questions/211436/why-do-we-normalize-images-by-subtracting-the-datasets-image-mean-and-not-the-c\n"
      ]
    }
  ]
}